{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "5bb92bf9d5f547c68e97a13c058a4ae2",
      "930eefef33c546378d97c90148d4d20f",
      "2b91d5187788498ab39a721d3e65030d",
      "da28cc82f9134af4a27765972a23da5b",
      "15c8fbe66f8e45abbee3e03d36da9885",
      "c8bd42f4dbce41bdaeccca21413c8910",
      "67717d0b76b14252b35fff36d41b7e3e",
      "c2ce4ce32abe4aaf84a3f8e01630dee0",
      "34f530b73f0a43ceadba99fed0f73a0e",
      "3e2cc41e3b2e42f6b00cbe775eef42b7",
      "08be7842cbf94384ac5f0abb159d3403"
     ]
    },
    "id": "rzNlmZHK2q1F",
    "outputId": "96e55c79-1be6-474e-a58f-bd68f719e3a6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b37997dc0a418ab7bf2615006e3b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3,4,5\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"]=\"/nfs/scistore19/alistgrp/huggingface/hub\"\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "model_name = \"Qwen/Qwen3-8B\"\n",
    "model_name = \"Qwen/Qwen3-32B\"\n",
    "model_name = \"google/gemma-3-27b-it\"\n",
    "#model_name = \"Qwen/Qwen3-4B-Base\"\n",
    "#model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# load the tokenizer and the model\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token  \n",
    "tokenizer.padding_side = \"left\"          \n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "training = (\n",
    "    pd.read_csv(\"data/training.csv\")\n",
    "      .sample(frac=1, random_state=SEED) \n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# example_3 = training.reset_index().iloc[100][\"sentence\"]\n",
    "# label_3 = training.reset_index().iloc[100][\"label\"]\n",
    "# example_2 = training.reset_index().iloc[101][\"sentence\"]\n",
    "# label_2 = training.reset_index().iloc[101][\"label\"]\n",
    "# example_1 = training.reset_index().iloc[195][\"sentence\"]\n",
    "# label_1 = training.reset_index().iloc[195][\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kindizAELQwA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom collections import Counter\\nlabel_counts = Counter(training[\"label\"])\\nprint(\"Label counts in the entire training dataset:\")\\nfor label, count in label_counts.items():\\n    print(f\"{label}: {count}\")\\nprint(\"Label distribution (percentage) in the training dataset:\")\\nprint((training[\"label\"].value_counts(normalize=True) * 100).round(2).astype(str) + \\'%\\')\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def generate_prompt(few_shot_samples, sentence):\n",
    "    promt_fun = lambda first_ex, first_label, second_ex, second_label, third_ex, third_label, sentence: f\"Answer in a single word positive, negative or neutral sentiment determining the sentiment of the following sentence. After Input: follows the sentence then write the correct sentiment after Output:. Here are three example: \\n Input: {first_ex} \\n Output: {first_label} \\n Input: {second_ex} \\n Output: {second_label} \\n Input: {third_ex} \\n Output: {third_label} \\n Input: {sentence} \\n Output: \"\n",
    "    #promt_fun = lambda first_ex, first_label, second_ex, second_label, third_ex, third_label, sentence: f\"Answer in a single word positive, negative or neutral sentiment determining the sentiment of the following sentence. After Input: follows the sentence then write the correct sentiment after Output:. Here is an example: \\n Input: {first_ex} \\n Output: {first_label} \\n Input: {sentence} \\n Output: \"\n",
    "    examples =  list(zip(training[\"sentence\"].iloc[:few_shot_samples], training[\"label\"].iloc[:few_shot_samples]))\n",
    "    prompt = (\n",
    "        \"You are a highly accurate sentiment classifier.\\n\\n\"\n",
    "        \"Your task is to classify the input sentence as 'positive', 'negative', or 'neutral'. \"\n",
    "        \"In case the input could be classified both as 'negative' and 'positive', classify as 'neutral'. \"\n",
    "        \"The input format is the following: After 'Input:' the sentence to classify follows. \"\n",
    "        \"Then, after 'Output:' you should respond with a single word. Either 'positive', 'negative', or 'neutral', \"\n",
    "        \"depending on the sentiment of the input sentence.\\n\"\n",
    "        + \"\\n\".join([f\"Input: {ex} Output: {label}\" for ex, label in examples])\n",
    "        + f\"\\nInput: {sentence} Output:\"\n",
    "    )\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "from collections import Counter\n",
    "label_counts = Counter(training[\"label\"])\n",
    "print(\"Label counts in the entire training dataset:\")\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")\n",
    "print(\"Label distribution (percentage) in the training dataset:\")\n",
    "print((training[\"label\"].value_counts(normalize=True) * 100).round(2).astype(str) + '%')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "for num_few_shot in [5,10,20,35]:\n",
    "    acc, score = inf(num_few_shot)\n",
    "    print(f\"num_few_shot: {num_few_shot} Accuracy: {(100*acc):.1f} Score: {(100*score):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tL8ySDXAO_kI",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "7f10dbd1-8065-48c3-eac6-868a1c9456a9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def inf(num_few_shot):\n",
    "\n",
    "  batch_size = 32\n",
    "  classi = []\n",
    "  true_labels = []\n",
    "  num_elements = 8*batch_size\n",
    "  for i in range(200, 200+num_elements, batch_size):\n",
    "    print(i)\n",
    "   \n",
    "    test_split = training.iloc[i:i+batch_size]\n",
    "    sentences = test_split[\"sentence\"]\n",
    "    prompts = [generate_prompt(num_few_shot, sen) for sen in sentences]\n",
    "    #prompts = [prompts[1],prompts[1]]\n",
    "    # print(prompts)\n",
    "    # prepare the model input\n",
    "\n",
    "    if \"it\" in model_name or \"Qwen\" in model_name: # instruction tuned\n",
    "      messages = [[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ] for prompt in prompts]\n",
    "      text = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True,\n",
    "                enable_thinking=False\n",
    "            )\n",
    "    else:\n",
    "      text = prompts\n",
    "  \n",
    "    model_inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(model.device)\n",
    "\n",
    "    # conduct text completion\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=2\n",
    "    )\n",
    "    output_ids = generated_ids[:,len(model_inputs.input_ids[0]):].tolist()\n",
    "    true_labels += test_split[\"label\"].tolist()\n",
    "    for j in range(len(output_ids)):\n",
    "      thinking_content = tokenizer.decode(output_ids[j], skip_special_tokens=True).strip(\"\\n\")\n",
    "      # print(\"=\"*100)\n",
    "      # print(thinking_content)\n",
    "      # print(\"=\"*100)\n",
    "      '''\n",
    "      if \"positive\" in thinking_content.lower():\n",
    "        classi.append(\"positive\")\n",
    "      elif \"negative\" in thinking_content.lower():\n",
    "        classi.append(\"negative\")\n",
    "      elif \"neutral\" in thinking_content.lower():\n",
    "        classi.append(\"neutral\")\n",
    "      else:\n",
    "        classi.append(\"unknown\")\n",
    "        #classi.append(\"neutral\")\n",
    "        print(\"Does not contain answer\")\n",
    "      '''\n",
    "      \n",
    "      content = thinking_content.lower()\n",
    "    \n",
    "      positions = {\n",
    "          \"positive\": content.rfind(\"positive\"),\n",
    "          \"negative\": content.rfind(\"negative\"),\n",
    "          \"neutral\": content.rfind(\"neutral\")\n",
    "      }\n",
    "    \n",
    "\n",
    "\n",
    "      # Filter out words that were not found (position = -1)\n",
    "      found_words = {k: v for k, v in positions.items() if v != -1}\n",
    "      #print(positions)\n",
    "      #print(found_words)\n",
    "      #print()\n",
    "\n",
    "      if found_words:\n",
    "          # Get the word with the maximum position (last to appear)\n",
    "          last_word = max(found_words, key=found_words.get)\n",
    "          classi.append(last_word)\n",
    "      else:\n",
    "          classi.append(\"neutral\")\n",
    "          print(\"unknown\")\n",
    "  print(classi.count(\"positive\"), classi.count(\"negative\"), classi.count(\"neutral\"))\n",
    "  \n",
    "  \n",
    "  pred_list = classi\n",
    "  true_list = true_labels\n",
    "  score = 0\n",
    "  ma = {\"positive\":0, \"neutral\":0.5, \"negative\":1}\n",
    "  for ele1, ele2 in zip(pred_list, true_list):\n",
    "     score += (1 - abs(ma[ele1]-ma[ele2]))/len(true_list)\n",
    "     \n",
    "  return (np.array(classi) == np.array(true_labels)).astype(int).mean(), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4ZQ47IxGrM-X"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_list \u001b[38;5;241m=\u001b[39m \u001b[43mclassi\u001b[49m\n\u001b[1;32m      2\u001b[0m true_list \u001b[38;5;241m=\u001b[39m true_labels\n\u001b[1;32m      3\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classi' is not defined"
     ]
    }
   ],
   "source": [
    "pred_list = classi\n",
    "true_list = true_labels\n",
    "score = 0\n",
    "ma = {\"positive\":0, \"neutral\":0.5, \"negative\":1}\n",
    "for ele1, ele2 in zip(pred_list, true_list):\n",
    "    score += (1 - abs(ma[ele1]-ma[ele2]))/len(true_list)\n",
    "    \n",
    "print((np.array(classi) == np.array(true_labels)).astype(int).mean(), score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oD7sCYzg_jm",
    "outputId": "bc2fbbb1-3234-43c0-d96c-86c5e0733add"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 169])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ly8wJcK8guD1",
    "outputId": "0f916c45-d8cd-4d97-b9e7-9ff8501ea651"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1957,   1437,    279,  25975,    315,    279,  11652,   2701,   5571,\n",
       "             25,   1119,   6785,     11,  20628,    323,   8225,     13,  21806,\n",
       "            304,    825,   3409,     13,    715,   5571,     25,   3216,  12872,\n",
       "           1052,    374,    264,  29039,   2114,    389,   1039,   1852,   8592,\n",
       "            702,   1012,    389,    279,   3081,    369,  57980,     50,     13,\n",
       "            715,   9258,     25,  20628,    715,   5571,     25,  20094,    498,\n",
       "           1035,   1366,    304,    264,    259,   5947,  39728,     13,    715,\n",
       "           9258,     25,   6785,    715,   5571,     25,   2411,    220,     16,\n",
       "             16,     15,  12348,   1039,   2310,   3720,  64324,   3937,    700,\n",
       "             13,    715,   9258,     25,   8225,    715,   5571,     25,  94292,\n",
       "          33828,   1279,    278,    329,   8013,     33,      8,    358,  14915,\n",
       "            279,   1473,     13,    715,   9258,     25,    220,     16,     13,\n",
       "           6785,    198,     17],\n",
       "        [  1957,   1437,    279,  25975,    315,    279,  11652,   2701,   5571,\n",
       "             25,   1119,   6785,     11,  20628,    323,   8225,     13,  21806,\n",
       "            304,    825,   3409,     13,    715,   5571,     25,   3216,  12872,\n",
       "           1052,    374,    264,  29039,   2114,    389,   1039,   1852,   8592,\n",
       "            702,   1012,    389,    279,   3081,    369,  57980,     50,     13,\n",
       "            715,   9258,     25,  20628,    715,   5571,     25,  20094,    498,\n",
       "           1035,   1366,    304,    264,    259,   5947,  39728,     13,    715,\n",
       "           9258,     25,   6785,    715,   5571,     25,   2411,    220,     16,\n",
       "             16,     15,  12348,   1039,   2310,   3720,  64324,   3937,    700,\n",
       "             13,    715,   9258,     25,   8225,    715,   5571,     25,   1446,\n",
       "           3378,    315,    614,    311,    614,    458,   6350,   1184,     13,\n",
       "            715,   9258,     25,    220, 151643, 151643, 151643,    576,  25975,\n",
       "            315,    279,  11652]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ic9MF5vgdBtx",
    "outputId": "5c09c56c-e3c3-4949-d120-04c75e2bd924"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[16, 13, 6785, 198, 17], [576, 25975, 315, 279, 11652]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "XywOPuipfjzc",
    "outputId": "2319a04f-2a66-45c4-8a13-ee9dc6b8fa99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Complaint... drinks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Most places had stopped serving breakfast at 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "204                                 Complaint... drinks.\n",
       "205    Most places had stopped serving breakfast at 1...\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKg6M6CkgYih",
    "outputId": "68a6362a-72c5-4e91-b6f4-bb50bd3a6574"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classify the sentiment of the sentence following Input: into positive, neutral and negative. Answer in one word. \\n Input: By contrast there is a comparable home on our same street has been on the market for MONTHS. \\n Output: neutral \\n Input: Everything you would want in a tanning salon. \\n Output: positive \\n Input: At 110 degrees our old air conditioner went out. \\n Output: negative \\n Input: Complaint... drinks. \\n Output: ',\n",
       " 'Classify the sentiment of the sentence following Input: into positive, neutral and negative. Answer in one word. \\n Input: By contrast there is a comparable home on our same street has been on the market for MONTHS. \\n Output: neutral \\n Input: Everything you would want in a tanning salon. \\n Output: positive \\n Input: At 110 degrees our old air conditioner went out. \\n Output: negative \\n Input: Most places had stopped serving breakfast at 11am. \\n Output: ']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwKM2-kJfn75",
    "outputId": "9364a766-b849-4c6a-ddee-ef9628e26c67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unknown',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'unknown',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'positive',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'unknown',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'neutral',\n",
       " 'unknown',\n",
       " 'negative',\n",
       " 'unknown',\n",
       " 'negative',\n",
       " 'neutral',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'negative',\n",
       " 'unknown',\n",
       " 'negative',\n",
       " 'unknown',\n",
       " 'neutral',\n",
       " 'unknown',\n",
       " 'neutral',\n",
       " 'unknown',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'unknown',\n",
       " 'neutral',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'neutral',\n",
       " 'positive',\n",
       " 'unknown',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'unknown',\n",
       " 'neutral',\n",
       " 'neutral']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85OW_oA2XlCO",
    "outputId": "9ca610d2-80e2-487e-a445-f89da58b5f11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.734375)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(classi) == np.array(true_labels)).astype(int).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDjKDoOb3Tg2"
   },
   "outputs": [],
   "source": [
    "prompts = [promt_fun(example_1, label_1, example_2, label_2, example_3, label_3, sen) for sen in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdvsxOc68lwB"
   },
   "outputs": [],
   "source": [
    "train_split[\"clas\"] = classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkWyze9x9mJr"
   },
   "outputs": [],
   "source": [
    "(train_split[\"clas\"] == train_split[\"label\"]).astype(int).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPwiE3av6_Us"
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZyvNEdu38EG"
   },
   "outputs": [],
   "source": [
    "# prepare the model input\n",
    "#prompt = \"Give me a short introduction to large language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt} for prompt in prompts\n",
    "]\n",
    "\"\"\"text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\"\"\"\n",
    "\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJODrNvE4EC1"
   },
   "outputs": [],
   "source": [
    "model_inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SPpL5fFE4qSe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DC9XZ_bJ5NG_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpHwSvXa5NVb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08be7842cbf94384ac5f0abb159d3403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15c8fbe66f8e45abbee3e03d36da9885": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b91d5187788498ab39a721d3e65030d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2ce4ce32abe4aaf84a3f8e01630dee0",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_34f530b73f0a43ceadba99fed0f73a0e",
      "value": 3
     }
    },
    "34f530b73f0a43ceadba99fed0f73a0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3e2cc41e3b2e42f6b00cbe775eef42b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bb92bf9d5f547c68e97a13c058a4ae2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_930eefef33c546378d97c90148d4d20f",
       "IPY_MODEL_2b91d5187788498ab39a721d3e65030d",
       "IPY_MODEL_da28cc82f9134af4a27765972a23da5b"
      ],
      "layout": "IPY_MODEL_15c8fbe66f8e45abbee3e03d36da9885"
     }
    },
    "67717d0b76b14252b35fff36d41b7e3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "930eefef33c546378d97c90148d4d20f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8bd42f4dbce41bdaeccca21413c8910",
      "placeholder": "​",
      "style": "IPY_MODEL_67717d0b76b14252b35fff36d41b7e3e",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "c2ce4ce32abe4aaf84a3f8e01630dee0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8bd42f4dbce41bdaeccca21413c8910": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da28cc82f9134af4a27765972a23da5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e2cc41e3b2e42f6b00cbe775eef42b7",
      "placeholder": "​",
      "style": "IPY_MODEL_08be7842cbf94384ac5f0abb159d3403",
      "value": " 3/3 [00:38&lt;00:00, 18.06s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
